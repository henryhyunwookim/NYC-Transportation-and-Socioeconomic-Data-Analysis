{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all requisite libraries, settings some overall parameters and formatting.\n",
    "%reset -f\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "#from pandas_profiling import ProfileReport\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 20\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "sns.set_style('darkgrid');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialCharactersFromStationName(df):\n",
    "    # Remove special characters from station names\n",
    "    df.station = df.station.str.replace(\"/\",\"_\")\n",
    "    df.station = df.station.str.replace(\"-\",\"_\")\n",
    "    df.station = df.station.str.replace(\" \",\"_\")\n",
    "    df.station = df.station.str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialCharactersFromStationTimestamps(df):\n",
    "    # Remove special characters from station dates\n",
    "    df['date'] = df['date'].str.replace('/','_')\n",
    "    df['time'] = df['time'].str.replace(':','_')\n",
    "    df['desc'] = df['desc'].str.replace(' ', '_')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStationCountsByTime(df, input_col, col_name='entry'):\n",
    "\n",
    "    df[col_name+'_day'] = df[input_col].dt.day\n",
    "    df[col_name+'_hour'] = df[input_col].dt.hour\n",
    "    df[col_name+'_weekday'] = df[input_col].dt.day_name()\n",
    "    df[col_name+'_year_month'] = df[input_col].dt.to_period('M')\n",
    "    print(f'\"{input_col}\" splitted into multiple columns.\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTrafficRidershipCounts(df):\n",
    "    # Creating the Net_Entries, Net_Exits, and Net_Traffic columns\n",
    "    df['net_entries'] = df.groupby(['control_area', 'unit', 'subunit_channel_pos', 'station'])['entries'].transform(lambda x: x.diff())\n",
    "    df['net_exits'] = df.groupby(['control_area', 'unit', 'subunit_channel_pos', 'station'])['exits'].transform(lambda x: x.diff())\n",
    "    df['net_traffic'] = df.net_entries + df.net_exits\n",
    "\n",
    "    # Elimating turnstiles that count in reverse by casting all values as absolutes.\n",
    "    df['net_entries'] = abs(df.net_entries)\n",
    "    df['net_exits'] = abs(df.net_exits)\n",
    "    df['net_traffic'] = abs(df.net_traffic)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutliers(df):\n",
    "    # Elimate outliers in the data by reducing to the 99th percentile. \n",
    "    q = np.nanquantile(df[\"net_entries\"], .99)\n",
    "    df = df[df[\"net_entries\"] < q]\n",
    "\n",
    "    q2 = np.nanquantile(df[\"net_exits\"], .99)\n",
    "    df = df[df[\"net_exits\"] < q2]\n",
    "\n",
    "    q3 = np.nanquantile(df['net_traffic'], .99)\n",
    "    df=df[df['net_traffic'] < q3]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialCharactersFromStopName(df):\n",
    "    df.stop_name = df.stop_name.str.replace(\" - \",\"_\")\n",
    "    df.stop_name = df.stop_name.str.replace(\" \",\"_\")\n",
    "    df.stop_name = df.stop_name.str.replace(\"(\",\"\")\n",
    "    df.stop_name = df.stop_name.str.replace(\")\",\"\")\n",
    "    df.stop_name = df.stop_name.str.replace(\"/\",\"_\")\n",
    "    df.stop_name = df.stop_name.str.replace(\".\",\"\")\n",
    "    df.stop_name = df.stop_name.str.replace(\"-\",\"_\")\n",
    "    df.stop_name = df.stop_name.str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchStationNames(df,df_gtfs):\n",
    "    \n",
    "    mat1 = []\n",
    "    mat2 = []\n",
    "    p= []\n",
    "    list1 = df.station.tolist()\n",
    "    list2 = df_gtfs.stop_name.tolist()\n",
    " \n",
    "    threshold = 50\n",
    "\n",
    "    for i in list1:\n",
    "        mat1.append(process.extractOne(i, list2, scorer=fuzz.ratio))\n",
    "    df['matches'] = mat1\n",
    "\n",
    "    for j in df['matches']:\n",
    "        if j[1] >= threshold:\n",
    "            p.append(j[0])\n",
    "\n",
    "        mat2.append(','.join(p))\n",
    "        p= []\n",
    "\n",
    "    df['matches'] = mat2\n",
    "    return df,df_gtfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rtree\n",
    "import pygeos\n",
    "def combineGTFSStopsAndStationData(df):\n",
    "   \n",
    "    df['geometry'] = [Point(xy) for xy in zip(np.array(df['gtfs_longitude']), np.array(df['gtfs_latitude']))]\n",
    "    gpd.options.use_pygeos = True\n",
    "    \n",
    "    cdta_map = gpd.read_file(\"..\\\\data\\\\nycdta2020_22b\\\\nycdta2020.shp\")\n",
    "    cdta_map.to_crs(4326, inplace=True)\n",
    "    \n",
    "    cdta_geo_df = cdta_map[['CDTA2020', 'CDTAName','geometry', 'Shape_Leng', 'Shape_Area','BoroName']].set_index('CDTA2020', drop=True)\n",
    "    \n",
    "    top_station_geo_df = gpd.GeoDataFrame(df, crs=4326, geometry = df.geometry)\n",
    "    top_station_geo_df.to_crs(4326, inplace=True)\n",
    "    \n",
    "    #df.to_csv('allstation1.csv')\n",
    "    # Locate each Station Point Geometry within NTA Polygon geometry\n",
    "    station_all_df = gpd.sjoin(cdta_geo_df,top_station_geo_df, how=\"left\", op=\"contains\")\n",
    "    station_all_df = station_all_df.reset_index()\n",
    "    \n",
    "    #print('before ctda cleanup')\n",
    "    #print(station_all_df.head(1))\n",
    "    #print(station_all_df.columns)\n",
    "    #print(station_all_df.shape)\n",
    "    \n",
    "    station_all_df = station_all_df[station_all_df['CDTA2020'].str.match('^[a-zA-Z]{2}\\d{2}$')]\n",
    "    \n",
    "    #print('after ctda cleanup')\n",
    "    #print(station_all_df.head(1))\n",
    "    #print(station_all_df.columns)\n",
    "    #print(station_all_df.shape)\n",
    "    \n",
    "    #Few stations that belong to Manhattan Burough were identified based on the CDTA code\n",
    "    station_all_df['borough'] = station_all_df.borough.fillna(\"M\")\n",
    "    \n",
    "    print('combineGTFSStopsAndStationData ouput..')\n",
    "    print(station_all_df.columns)   \n",
    "    print(station_all_df.head(1))\n",
    "    cdta_dict = cdta_map[[\"CDTA2020\", \"CDTAName\"]].set_index(\"CDTA2020\").to_dict()[\"CDTAName\"]\n",
    "    return station_all_df,cdta_dict   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5287402, 16)\n",
      "after removng days in 2021\n",
      "(5082415, 16)\n",
      "\"date_time\" splitted into multiple columns.\n",
      "\n",
      "\"date_time\" splitted into multiple columns.\n",
      "\n",
      "Index(['control_area', 'unit', 'subunit_channel_pos', 'station',\n",
      "       'subway_lines', 'division', 'date', 'time', 'desc', 'entries', 'exits',\n",
      "       'unique_id', 'date_time', 'net_entries', 'net_exits', 'net_traffic',\n",
      "       'Station_Readings_Entry_day', 'Station_Readings_Entry_hour',\n",
      "       'Station_Readings_Entry_weekday', 'Station_Readings_Entry_year_month',\n",
      "       'Station_Readings_Exit_day', 'Station_Readings_Exit_hour',\n",
      "       'Station_Readings_Exit_weekday', 'Station_Readings_Exit_year_month'],\n",
      "      dtype='object')\n",
      "(5082415, 24)\n",
      "  control_area  unit subunit_channel_pos station subway_lines division  \\\n",
      "0         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "1         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "2         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "3         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "4         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "5         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "6         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "7         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "8         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "9         A002  R051            02_00_00   59_st      NQR456W      BMT   \n",
      "\n",
      "         date      time     desc  entries  ...  net_exits net_traffic  \\\n",
      "0  06_18_2022  00_00_00  REGULAR  7726949  ...        0.0         0.0   \n",
      "1  06_18_2022  04_00_00  REGULAR  7726955  ...        8.0        14.0   \n",
      "2  06_18_2022  08_00_00  REGULAR  7726964  ...       24.0        33.0   \n",
      "3  06_18_2022  12_00_00  REGULAR  7726999  ...       84.0       119.0   \n",
      "4  06_18_2022  16_00_00  REGULAR  7727100  ...       42.0       143.0   \n",
      "5  06_18_2022  20_00_00  REGULAR  7727190  ...       50.0       140.0   \n",
      "6  06_19_2022  00_00_00  REGULAR  7727254  ...       27.0        91.0   \n",
      "7  06_19_2022  04_00_00  REGULAR  7727259  ...        8.0        13.0   \n",
      "8  06_19_2022  08_00_00  REGULAR  7727262  ...       10.0        13.0   \n",
      "9  06_19_2022  12_00_00  REGULAR  7727291  ...       53.0        82.0   \n",
      "\n",
      "  Station_Readings_Entry_day  Station_Readings_Entry_hour  \\\n",
      "0                         18                            0   \n",
      "1                         18                            4   \n",
      "2                         18                            8   \n",
      "3                         18                           12   \n",
      "4                         18                           16   \n",
      "5                         18                           20   \n",
      "6                         19                            0   \n",
      "7                         19                            4   \n",
      "8                         19                            8   \n",
      "9                         19                           12   \n",
      "\n",
      "   Station_Readings_Entry_weekday  Station_Readings_Entry_year_month  \\\n",
      "0                        Saturday                            2022-06   \n",
      "1                        Saturday                            2022-06   \n",
      "2                        Saturday                            2022-06   \n",
      "3                        Saturday                            2022-06   \n",
      "4                        Saturday                            2022-06   \n",
      "5                        Saturday                            2022-06   \n",
      "6                          Sunday                            2022-06   \n",
      "7                          Sunday                            2022-06   \n",
      "8                          Sunday                            2022-06   \n",
      "9                          Sunday                            2022-06   \n",
      "\n",
      "   Station_Readings_Exit_day  Station_Readings_Exit_hour  \\\n",
      "0                         18                           0   \n",
      "1                         18                           4   \n",
      "2                         18                           8   \n",
      "3                         18                          12   \n",
      "4                         18                          16   \n",
      "5                         18                          20   \n",
      "6                         19                           0   \n",
      "7                         19                           4   \n",
      "8                         19                           8   \n",
      "9                         19                          12   \n",
      "\n",
      "  Station_Readings_Exit_weekday Station_Readings_Exit_year_month  \n",
      "0                      Saturday                          2022-06  \n",
      "1                      Saturday                          2022-06  \n",
      "2                      Saturday                          2022-06  \n",
      "3                      Saturday                          2022-06  \n",
      "4                      Saturday                          2022-06  \n",
      "5                      Saturday                          2022-06  \n",
      "6                        Sunday                          2022-06  \n",
      "7                        Sunday                          2022-06  \n",
      "8                        Sunday                          2022-06  \n",
      "9                        Sunday                          2022-06  \n",
      "\n",
      "[10 rows x 24 columns]\n",
      "Stations With passenger counts and timestamps ,net entries and net exits and net traffic(which is sum of net entry and exit\n"
     ]
    }
   ],
   "source": [
    "#1. Load first six months of 2022 Ridership data for subway stations using Turnstile datasource.\n",
    "\n",
    "engine = create_engine(\"sqlite:///C:\\\\Users\\\\panch\\\\finaldeliverable\\\\NYC-Transportation-and-Socioeconomic-Data-Analysis\\\\subway\\\\notebooks\\\\mta_data.db\")\n",
    "mta_df = pd.read_sql('SELECT * FROM mta_data;', engine)\n",
    "\n",
    "#Cleanup data from station names\n",
    "# Rename mta_df columns to make them easier to work wit\n",
    "mta_df = mta_df.rename(columns={'C/A': 'control_area', 'UNIT': 'unit', 'SCP': 'subunit_channel_pos', 'STATION':'station', 'LINENAME':'subway_lines', 'DIVISION':'division', 'DATE':'date', 'TIME':'time', 'DESC':'desc', 'ENTRIES':'entries', 'EXITS':'exits'})\n",
    "mta_df = removeSpecialCharactersFromStationName(mta_df)\n",
    "mta_df = removeSpecialCharactersFromStationTimestamps(mta_df)\n",
    "\n",
    "mta_df['subunit_channel_pos'] = mta_df['subunit_channel_pos'].str.replace('-', '_')\n",
    "\n",
    "# Create UniqueId column for grouping by \n",
    "mta_df['unique_id'] = mta_df['control_area'] + '_' + mta_df['unit'] + '_' + mta_df['subunit_channel_pos'] + '_' + mta_df['station'] + '_' + mta_df['date'] + '_' + mta_df['time'] + '_' + mta_df['desc']\n",
    "mta_df['date_time'] = mta_df.date + ' ' + mta_df.time\n",
    "mta_df.date_time = pd.to_datetime(mta_df['date_time'], format = '%m_%d_%Y %H_%M_%S')\n",
    "mta_df = mta_df[mta_df.desc != 'RECOVR_AUD']\n",
    "\n",
    "mta_df = computeTrafficRidershipCounts(mta_df)\n",
    "mta_df.fillna(0, inplace=True)\n",
    "\n",
    "# Elimate outliers in the data by reducing to the 99th percentile. \n",
    "mta_df = removeOutliers(mta_df)\n",
    "\n",
    "print(mta_df.shape)\n",
    "\n",
    "mta_df = mta_df[(mta_df['date_time']>pd.Timestamp(2022,1,1)) & (mta_df['date_time']<pd.Timestamp(2022,7,1))]\n",
    "print('after removng days in 2021')\n",
    "print(mta_df.shape)\n",
    "\n",
    "mta_df = createStationCountsByTime(mta_df, 'date_time', col_name='Station_Readings_Entry')\n",
    "mta_df = createStationCountsByTime(mta_df, 'date_time', col_name='Station_Readings_Exit')\n",
    "\n",
    "\n",
    "print(mta_df.columns)\n",
    "print(mta_df.shape)\n",
    "print(mta_df.head(10))\n",
    "\n",
    "print('Stations With passenger counts and timestamps ,net entries and net exits and net traffic(which is sum of net entry and exit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\2532346317.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.stop_name = df.stop_name.str.replace(\"(\",\"\")\n",
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\2532346317.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.stop_name = df.stop_name.str.replace(\")\",\"\")\n",
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\2532346317.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.stop_name = df.stop_name.str.replace(\".\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combineGTFSStopsAndStationData ouput..\n",
      "Index(['CDTA2020', 'CDTAName', 'geometry', 'Shape_Leng', 'Shape_Area',\n",
      "       'BoroName', 'index_right', 'station', 'net_traffic', 'matches',\n",
      "       'ogc_fid', 'station_id', 'complex_id', 'gtfs_stop_id', 'division',\n",
      "       'line', 'stop_name', 'borough', 'daytime_routes', 'structure',\n",
      "       'gtfs_latitude', 'gtfs_longitude', 'north_direction_label',\n",
      "       'south_direction_label'],\n",
      "      dtype='object')\n",
      "  CDTA2020                                        CDTAName  \\\n",
      "0     BK01  BK01 Williamsburg-Greenpoint (CD 1 Equivalent)   \n",
      "\n",
      "                                            geometry    Shape_Leng  \\\n",
      "0  POLYGON ((-73.92406 40.71411, -73.92404 40.714...  65655.741577   \n",
      "\n",
      "     Shape_Area  BoroName  index_right      station  net_traffic      matches  \\\n",
      "0  1.316597e+08  Brooklyn        244.0  flushing_av    1645919.0  flushing_av   \n",
      "\n",
      "   ...  division       line    stop_name borough daytime_routes structure  \\\n",
      "0  ...       IND  Crosstown  flushing_av      Bk              G    Subway   \n",
      "\n",
      "  gtfs_latitude gtfs_longitude north_direction_label south_direction_label  \n",
      "0     40.700377     -73.950234                Queens             Church Av  \n",
      "\n",
      "[1 rows x 24 columns]\n",
      "(505, 24)\n",
      "(504, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panch\\miniconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:127: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "source": [
    "#2. Load GTFS stop data for mapping Borough and CDTA using Lat and Long geometry to station data.\n",
    "cols_to_keep = [\"station\",\"entries\", \"exits\",\"net_entries\",\"net_exits\",\"net_traffic\",\"Station_Readings_Exit_weekday\",\"Station_Readings_Exit_year_month\",\"Station_Readings_Exit_day\",\"Station_Readings_Exit_hour\",\"Station_Readings_Entry_weekday\",\"Station_Readings_Entry_year_month\",\"Station_Readings_Entry_day\",\"Station_Readings_Entry_hour\"]\n",
    "group_cols = [\"net_traffic\"]\n",
    "\n",
    "station_data_gtfs = pd.read_csv('../data/subway/stationnames.csv')\n",
    "station_data_gtfs = removeSpecialCharactersFromStopName(station_data_gtfs)\n",
    "\n",
    "mta_df = mta_df[cols_to_keep]\n",
    "                \n",
    "top_stations = mta_df.groupby('station')[group_cols].sum().sort_values(by='net_traffic', ascending=False).reset_index().copy()\n",
    "\n",
    "top_stations,station_data_gtfs = matchStationNames(top_stations,station_data_gtfs)\n",
    "\n",
    "#Merge station names from GTFS and Turnstile data for mapping CDTA\n",
    "top_station_df = pd.merge(top_stations, right=station_data_gtfs, left_on='matches', right_on='stop_name', how='left')\n",
    "\n",
    "#Merge CDTA Code and Burough code into single DF\n",
    "stationWithCdta,cdta_dict = combineGTFSStopsAndStationData(top_station_df)\n",
    "stationWithCdta.dropna(subset=['station'], how='all', inplace=True)\n",
    "#stationWithCdta.info() \n",
    "\n",
    "stationWithCdta = stationWithCdta.rename(columns={'CDTA2020': 'cdtaCode'})\n",
    "print(stationWithCdta.shape)\n",
    "\n",
    "#station name is mapped to wrong borough\n",
    "stationWithCdta = stationWithCdta.drop(stationWithCdta.index[226])\n",
    "print(stationWithCdta.shape)\n",
    "\n",
    "#Create CDTA Dictionary\n",
    "cdta_station_dict = stationWithCdta[[\"cdtaCode\", \"station\"]].set_index(\"station\").to_dict()[\"cdtaCode\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['BK03', 'BK01', 'BK01', 'BK01', 'BK01', 'BK01', 'BK01', 'BK01', 'QN01', 'BK01', 'BK01', 'MN03', 'BK01', 'BK06', 'BK02', 'MN01', 'BK02', 'BK02', 'BK02', 'BK06', 'BK02', 'BK02', 'BK02', 'BK02', 'BK02', 'BK02', 'BK02', 'BK02', 'BK02', 'BK04', 'BK02', 'BK09', 'BK03', 'BK03', 'BK09', 'BK03', 'BK03', 'BK03', 'BK16', 'BK04', 'QN05', 'BK04', 'BK04', 'BK04', 'BK04', 'BK04', 'BK04', 'BK04', 'BK05', 'BK05', 'BK05', 'BK05', 'BK16', 'BK16', 'BK05', 'BK05', 'BK05', 'BK05', 'BK05', 'BK05', 'BK05', 'BK05', 'BK05', 'BK05', 'MN05', 'BK06', 'MN02', 'BK06', 'BK06', 'BK06', 'MN04', 'BK07', 'BX01', 'BK12', 'BK07', 'MN08', 'BK07', 'BK07', 'QN01', 'MN01', 'BK09', 'BK09', 'BK09', 'BK09', 'BK09', 'BK09', 'BK09', 'BK09', 'BK09', 'BK10', 'MN64', 'MN08', 'BK10', 'BK11', 'BK14', 'MN07', 'BK11', 'BK11', 'BK12', 'BK11', 'BK15', 'BK15', 'BK12', 'MN05', 'BK12', 'BK12', 'BK12', 'BK12', 'BK17', 'BK12', 'BK13', 'BK13', 'BK13', 'BK13', 'BK13', 'BK13', 'BK13', 'BK13', 'BK14', 'BK14', 'BK14', 'BK14', 'BK14', 'BK14', 'BK14', 'BK15', 'BK15', 'BK16', 'BK16', 'BK16', 'BK16', 'BK16', 'BK16', 'BK16', 'BK16', 'BK16', 'BK16', 'BK17', 'BK17', 'BK17', 'BK17', 'BK17', 'BK18', 'BK55', 'BX01', 'BX01', 'BX01', 'BX01', 'BX01', 'BX01', 'BX01', 'BX01', 'BX02', 'BX02', 'BX02', 'BX02', 'BX02', 'BX02', 'BX03', 'BX03', 'BX04', 'BX04', 'BX04', 'BX04', 'BX05', 'BX05', 'BX05', 'BX05', 'BX05', 'BX05', 'BX07', 'BX06', 'BX06', 'BX06', 'BX07', 'BX07', 'BX07', 'BX07', 'BX07', 'BX08', 'BX08', 'BX09', 'BX09', 'BX09', 'BX09', 'BX10', 'BX10', 'BX10', 'BX10', 'BX10', 'BX10', 'BX11', 'BX11', 'BX11', 'BX12', 'BX12', 'BX12', 'BX12', 'BX12', 'BX12', 'BX12', 'BX12', 'BX12', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN01', 'MN02', 'MN02', 'MN02', 'MN02', 'MN02', 'MN02', 'MN02', 'MN02', 'MN02', 'MN02', 'MN04', 'MN04', 'MN02', 'MN03', 'MN03', 'MN03', 'MN03', 'MN03', 'MN04', 'MN05', 'MN05', 'QN02', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN06', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN05', 'MN06', 'MN06', 'MN06', 'MN64', 'MN07', 'MN07', 'MN64', 'MN64', 'MN07', 'MN08', 'MN08', 'MN08', 'MN08', 'MN10', 'MN09', 'MN11', 'MN09', 'MN10', 'MN10', 'MN10', 'MN11', 'MN10', 'MN11', 'MN12', 'MN12', 'MN12', 'MN12', 'MN12', 'MN12', 'MN12', 'MN12', 'MN12', 'MN12', 'MN12', 'MN64', 'MN64', 'MN64', 'QN01', 'QN01', 'QN01', 'QN01', 'QN02', 'QN01', 'QN01', 'QN01', 'QN01', 'QN02', 'QN02', 'QN02', 'QN02', 'QN02', 'QN02', 'QN02', 'QN02', 'QN02', 'QN02', 'QN03', 'QN03', 'QN03', 'QN10', 'QN09', 'QN04', 'QN04', 'QN04', 'QN04', 'QN04', 'QN04', 'QN05', 'QN05', 'QN05', 'QN06', 'QN06', 'QN06', 'QN06', 'QN07', 'QN09', 'QN10', 'QN09', 'QN09', 'QN09', 'QN10', 'QN10', 'QN10', 'QN10', 'QN10', 'QN10', 'QN12', 'QN12', 'QN12', 'QN12', 'QN12', 'QN12', 'QN12', 'QN14', 'QN14', 'QN14', 'QN14', 'QN14', 'QN14', 'QN14', 'QN14', 'QN14', 'QN14', 'QN81', 'QN81', 'QN83', 'SI01', 'SI01'])\n"
     ]
    }
   ],
   "source": [
    "print(cdta_station_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['station', 'entries', 'exits', 'net_entries', 'net_exits',\n",
      "       'net_traffic', 'Station_Readings_Exit_weekday',\n",
      "       'Station_Readings_Exit_year_month', 'Station_Readings_Exit_day',\n",
      "       'Station_Readings_Exit_hour', 'Station_Readings_Entry_weekday',\n",
      "       'Station_Readings_Entry_year_month', 'Station_Readings_Entry_day',\n",
      "       'Station_Readings_Entry_hour'],\n",
      "      dtype='object')\n",
      "(57, 1)\n",
      "(57, 1)\n",
      "          net_entries\n",
      "cdtaCode             \n",
      "BK01        5813770.0\n",
      "           net_exits\n",
      "cdtaCode            \n",
      "BK01      10136488.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1987195146.py:9: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  net_entry_cdta = net_entry_stations.groupby(['cdtaCode']).sum()\n",
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1987195146.py:10: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  net_exit_cdta = net_exit_stations.groupby(['cdtaCode']).sum()\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate CDTA NetEntries and NetExits\n",
    "print(mta_df.columns)\n",
    "net_entry_stations = mta_df.groupby(['station'])[\"net_entries\"].sum().reset_index().copy()\n",
    "net_exit_stations = mta_df.groupby(['station'])[\"net_exits\"].sum().reset_index().copy()\n",
    "\n",
    "net_entry_stations['cdtaCode'] = net_entry_stations['station'].map(cdta_station_dict).dropna()\n",
    "net_exit_stations['cdtaCode'] = net_exit_stations['station'].map(cdta_station_dict).dropna()\n",
    "\n",
    "net_entry_cdta = net_entry_stations.groupby(['cdtaCode']).sum()\n",
    "net_exit_cdta = net_exit_stations.groupby(['cdtaCode']).sum()\n",
    "\n",
    "print(net_entry_cdta.shape)\n",
    "print(net_exit_cdta.shape)\n",
    "\n",
    "print(net_entry_cdta.head(1))\n",
    "print(net_exit_cdta.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['station', 'entries', 'exits', 'net_entries', 'net_exits',\n",
      "       'net_traffic', 'Station_Readings_Exit_weekday',\n",
      "       'Station_Readings_Exit_year_month', 'Station_Readings_Exit_day',\n",
      "       'Station_Readings_Exit_hour', 'Station_Readings_Entry_weekday',\n",
      "       'Station_Readings_Entry_year_month', 'Station_Readings_Entry_day',\n",
      "       'Station_Readings_Entry_hour'],\n",
      "      dtype='object')\n",
      "(57, 31)\n",
      "(57, 31)\n",
      "          Entry_total_trip_count_day_1  Entry_total_trip_count_day_2  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          187210.0                      193948.0   \n",
      "\n",
      "          Entry_total_trip_count_day_3  Entry_total_trip_count_day_4  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          215215.0                      204971.0   \n",
      "\n",
      "          Entry_total_trip_count_day_5  Entry_total_trip_count_day_6  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          189750.0                      189721.0   \n",
      "\n",
      "          Entry_total_trip_count_day_7  Entry_total_trip_count_day_8  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          205888.0                      205006.0   \n",
      "\n",
      "          Entry_total_trip_count_day_9  Entry_total_trip_count_day_10  ...  \\\n",
      "cdtaCode                                                               ...   \n",
      "BK01                          196946.0                       223724.0  ...   \n",
      "\n",
      "          Entry_total_trip_count_day_22  Entry_total_trip_count_day_23  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                           194654.0                       199996.0   \n",
      "\n",
      "          Entry_total_trip_count_day_24  Entry_total_trip_count_day_25  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                           218084.0                       193284.0   \n",
      "\n",
      "          Entry_total_trip_count_day_26  Entry_total_trip_count_day_27  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                           158095.0                       158346.0   \n",
      "\n",
      "          Entry_total_trip_count_day_28  Entry_total_trip_count_day_29  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                           172061.0                       116571.0   \n",
      "\n",
      "          Entry_total_trip_count_day_30  Entry_total_trip_count_day_31  \n",
      "cdtaCode                                                                \n",
      "BK01                           101699.0                       112812.0  \n",
      "\n",
      "[1 rows x 31 columns]\n",
      "          Exit_total_trip_count_day_1  Exit_total_trip_count_day_2  \\\n",
      "cdtaCode                                                             \n",
      "BK01                         320164.0                     333817.0   \n",
      "\n",
      "          Exit_total_trip_count_day_3  Exit_total_trip_count_day_4  \\\n",
      "cdtaCode                                                             \n",
      "BK01                         365521.0                     338168.0   \n",
      "\n",
      "          Exit_total_trip_count_day_5  Exit_total_trip_count_day_6  \\\n",
      "cdtaCode                                                             \n",
      "BK01                         339166.0                     333466.0   \n",
      "\n",
      "          Exit_total_trip_count_day_7  Exit_total_trip_count_day_8  \\\n",
      "cdtaCode                                                             \n",
      "BK01                         339795.0                     355091.0   \n",
      "\n",
      "          Exit_total_trip_count_day_9  Exit_total_trip_count_day_10  ...  \\\n",
      "cdtaCode                                                             ...   \n",
      "BK01                         343772.0                      382398.0  ...   \n",
      "\n",
      "          Exit_total_trip_count_day_22  Exit_total_trip_count_day_23  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          350761.0                      357091.0   \n",
      "\n",
      "          Exit_total_trip_count_day_24  Exit_total_trip_count_day_25  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          386997.0                      323001.0   \n",
      "\n",
      "          Exit_total_trip_count_day_26  Exit_total_trip_count_day_27  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          270503.0                      279970.0   \n",
      "\n",
      "          Exit_total_trip_count_day_28  Exit_total_trip_count_day_29  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          288808.0                      218724.0   \n",
      "\n",
      "          Exit_total_trip_count_day_30  Exit_total_trip_count_day_31  \n",
      "cdtaCode                                                              \n",
      "BK01                          189856.0                      184907.0  \n",
      "\n",
      "[1 rows x 31 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1926805910.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  entry_day_count_cdta = day_entry_stations.groupby(['cdtaCode', 'Station_Readings_Entry_day']).sum().reset_index()\\\n",
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1926805910.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  exit_day_count_cdta = day_exit_stations.groupby(['cdtaCode', 'Station_Readings_Exit_day']).sum().reset_index()\\\n"
     ]
    }
   ],
   "source": [
    "# 4. Calculate CDTA Day wise (1 to 31 ) NetEntries and NetExits\n",
    "\n",
    "print(mta_df.columns)\n",
    "day_entry_stations = mta_df.groupby(['Station_Readings_Entry_day','station'])[\"net_entries\"].sum().reset_index().copy()\n",
    "day_exit_stations = mta_df.groupby(['Station_Readings_Exit_day','station'])[\"net_exits\"].sum().reset_index().copy()\n",
    "\n",
    "day_entry_stations['cdtaCode'] = day_entry_stations['station'].map(cdta_station_dict).dropna()\n",
    "day_exit_stations['cdtaCode'] = day_exit_stations['station'].map(cdta_station_dict).dropna()\n",
    "\n",
    "## Entry day count by CDTA\n",
    "entry_day_count_cdta = day_entry_stations.groupby(['cdtaCode', 'Station_Readings_Entry_day']).sum().reset_index()\\\n",
    "    [['cdtaCode', 'Station_Readings_Entry_day','net_entries']].pivot(index='cdtaCode', columns=\"Station_Readings_Entry_day\", values=\"net_entries\")\n",
    "entry_day_count_cdta.columns = [\"Entry_total_trip_count_day_\" + str(col) for col in entry_day_count_cdta.columns]\n",
    "\n",
    "## Exit day count by CDTA\n",
    "exit_day_count_cdta = day_exit_stations.groupby(['cdtaCode', 'Station_Readings_Exit_day']).sum().reset_index()\\\n",
    "    [['cdtaCode', 'Station_Readings_Exit_day','net_exits']].pivot(index='cdtaCode', columns=\"Station_Readings_Exit_day\", values=\"net_exits\")\n",
    "exit_day_count_cdta.columns = [\"Exit_total_trip_count_day_\" + str(col) for col in exit_day_count_cdta.columns]\n",
    "\n",
    "print(entry_day_count_cdta.shape)\n",
    "print(exit_day_count_cdta.shape)\n",
    "\n",
    "print(entry_day_count_cdta.head(1))\n",
    "print(exit_day_count_cdta.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['station', 'entries', 'exits', 'net_entries', 'net_exits',\n",
      "       'net_traffic', 'Station_Readings_Exit_weekday',\n",
      "       'Station_Readings_Exit_year_month', 'Station_Readings_Exit_day',\n",
      "       'Station_Readings_Exit_hour', 'Station_Readings_Entry_weekday',\n",
      "       'Station_Readings_Entry_year_month', 'Station_Readings_Entry_day',\n",
      "       'Station_Readings_Entry_hour'],\n",
      "      dtype='object')\n",
      "(57, 24)\n",
      "(57, 24)\n",
      "          Exit_total_trip_count_hour_0  Exit_total_trip_count_hour_1  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          764468.0                      245671.0   \n",
      "\n",
      "          Exit_total_trip_count_hour_2  Exit_total_trip_count_hour_3  \\\n",
      "cdtaCode                                                               \n",
      "BK01                               NaN                      104974.0   \n",
      "\n",
      "          Exit_total_trip_count_hour_4  Exit_total_trip_count_hour_5  \\\n",
      "cdtaCode                                                               \n",
      "BK01                          188527.0                       65138.0   \n",
      "\n",
      "          Exit_total_trip_count_hour_6  Exit_total_trip_count_hour_7  \\\n",
      "cdtaCode                                                               \n",
      "BK01                             337.0                      127722.0   \n",
      "\n",
      "          Exit_total_trip_count_hour_8  Exit_total_trip_count_hour_9  ...  \\\n",
      "cdtaCode                                                              ...   \n",
      "BK01                          521986.0                      308306.0  ...   \n",
      "\n",
      "          Exit_total_trip_count_hour_14  Exit_total_trip_count_hour_15  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                             1155.0                       526101.0   \n",
      "\n",
      "          Exit_total_trip_count_hour_16  Exit_total_trip_count_hour_17  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                          1234967.0                       494996.0   \n",
      "\n",
      "          Exit_total_trip_count_hour_18  Exit_total_trip_count_hour_19  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                             1086.0                       758178.0   \n",
      "\n",
      "          Exit_total_trip_count_hour_20  Exit_total_trip_count_hour_21  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                          1692852.0                       631265.0   \n",
      "\n",
      "          Exit_total_trip_count_hour_22  Exit_total_trip_count_hour_23  \n",
      "cdtaCode                                                                \n",
      "BK01                                NaN                       510340.0  \n",
      "\n",
      "[1 rows x 24 columns]\n",
      "          Entry_total_trip_count_hour_0  Entry_total_trip_count_hour_1  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                           323214.0                        96418.0   \n",
      "\n",
      "          Entry_total_trip_count_hour_2  Entry_total_trip_count_hour_3  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                                NaN                        50590.0   \n",
      "\n",
      "          Entry_total_trip_count_hour_4  Entry_total_trip_count_hour_5  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                            76405.0                        26733.0   \n",
      "\n",
      "          Entry_total_trip_count_hour_6  Entry_total_trip_count_hour_7  \\\n",
      "cdtaCode                                                                 \n",
      "BK01                              254.0                        83702.0   \n",
      "\n",
      "          Entry_total_trip_count_hour_8  Entry_total_trip_count_hour_9  ...  \\\n",
      "cdtaCode                                                                ...   \n",
      "BK01                           376738.0                       231791.0  ...   \n",
      "\n",
      "          Entry_total_trip_count_hour_14  Entry_total_trip_count_hour_15  \\\n",
      "cdtaCode                                                                   \n",
      "BK01                               755.0                        322859.0   \n",
      "\n",
      "          Entry_total_trip_count_hour_16  Entry_total_trip_count_hour_17  \\\n",
      "cdtaCode                                                                   \n",
      "BK01                            748120.0                        326888.0   \n",
      "\n",
      "          Entry_total_trip_count_hour_18  Entry_total_trip_count_hour_19  \\\n",
      "cdtaCode                                                                   \n",
      "BK01                               662.0                        454620.0   \n",
      "\n",
      "          Entry_total_trip_count_hour_20  Entry_total_trip_count_hour_21  \\\n",
      "cdtaCode                                                                   \n",
      "BK01                            819888.0                        287416.0   \n",
      "\n",
      "          Entry_total_trip_count_hour_22  Entry_total_trip_count_hour_23  \n",
      "cdtaCode                                                                  \n",
      "BK01                                 NaN                        212888.0  \n",
      "\n",
      "[1 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1115902608.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  entry_hour_count_cdta = hour_entry_stations.groupby(['cdtaCode', 'Station_Readings_Entry_hour']).sum().reset_index()\\\n",
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1115902608.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  exit_hour_count_cdta = hour_exit_stations.groupby(['cdtaCode', 'Station_Readings_Exit_hour']).sum().reset_index()\\\n"
     ]
    }
   ],
   "source": [
    "#5. Calculate CDTA Hour wise (1 to 24 ) NetEntries and NetExits\n",
    "\n",
    "print(mta_df.columns)\n",
    "hour_entry_stations = mta_df.groupby(['Station_Readings_Entry_hour','station'])[\"net_entries\"].sum().reset_index().copy()\n",
    "hour_exit_stations = mta_df.groupby(['Station_Readings_Exit_hour','station'])[\"net_exits\"].sum().reset_index().copy()\n",
    "\n",
    "hour_entry_stations['cdtaCode'] = hour_entry_stations['station'].map(cdta_station_dict).dropna()\n",
    "hour_exit_stations['cdtaCode'] = hour_exit_stations['station'].map(cdta_station_dict).dropna()\n",
    "\n",
    " ## Entry Hour count by CDTA\n",
    "entry_hour_count_cdta = hour_entry_stations.groupby(['cdtaCode', 'Station_Readings_Entry_hour']).sum().reset_index()\\\n",
    "    [['cdtaCode', 'Station_Readings_Entry_hour','net_entries']].pivot(index='cdtaCode', columns=\"Station_Readings_Entry_hour\", values=\"net_entries\")\n",
    "entry_hour_count_cdta.columns = [\"Entry_total_trip_count_hour_\" + str(col) for col in entry_hour_count_cdta.columns]\n",
    "\n",
    " ##  Exit Hour count by CDTA\n",
    "exit_hour_count_cdta = hour_exit_stations.groupby(['cdtaCode', 'Station_Readings_Exit_hour']).sum().reset_index()\\\n",
    "    [['cdtaCode', 'Station_Readings_Exit_hour','net_exits']].pivot(index='cdtaCode', columns=\"Station_Readings_Exit_hour\", values=\"net_exits\")\n",
    "exit_hour_count_cdta.columns = [\"Exit_total_trip_count_hour_\" + str(col) for col in exit_hour_count_cdta.columns]\n",
    "\n",
    "print(exit_hour_count_cdta.shape)\n",
    "print(entry_hour_count_cdta.shape)\n",
    "\n",
    "\n",
    "print(exit_hour_count_cdta.head(1))\n",
    "print(entry_hour_count_cdta.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['station', 'entries', 'exits', 'net_entries', 'net_exits',\n",
      "       'net_traffic', 'Station_Readings_Exit_weekday',\n",
      "       'Station_Readings_Exit_year_month', 'Station_Readings_Exit_day',\n",
      "       'Station_Readings_Exit_hour', 'Station_Readings_Entry_weekday',\n",
      "       'Station_Readings_Entry_year_month', 'Station_Readings_Entry_day',\n",
      "       'Station_Readings_Entry_hour'],\n",
      "      dtype='object')\n",
      "(57, 7)\n",
      "(57, 7)\n",
      "          Exit_total_trip_count_weekday_Friday  \\\n",
      "cdtaCode                                         \n",
      "BK01                                 1672489.0   \n",
      "\n",
      "          Exit_total_trip_count_weekday_Monday  \\\n",
      "cdtaCode                                         \n",
      "BK01                                 1410135.0   \n",
      "\n",
      "          Exit_total_trip_count_weekday_Saturday  \\\n",
      "cdtaCode                                           \n",
      "BK01                                   1068129.0   \n",
      "\n",
      "          Exit_total_trip_count_weekday_Sunday  \\\n",
      "cdtaCode                                         \n",
      "BK01                                 1165246.0   \n",
      "\n",
      "          Exit_total_trip_count_weekday_Thursday  \\\n",
      "cdtaCode                                           \n",
      "BK01                                   1644535.0   \n",
      "\n",
      "          Exit_total_trip_count_weekday_Tuesday  \\\n",
      "cdtaCode                                          \n",
      "BK01                                  1545492.0   \n",
      "\n",
      "          Exit_total_trip_count_weekday_Wednesday  \n",
      "cdtaCode                                           \n",
      "BK01                                    1630462.0  \n",
      "          Entry_total_trip_count_weekday_Friday  \\\n",
      "cdtaCode                                          \n",
      "BK01                                   962393.0   \n",
      "\n",
      "          Entry_total_trip_count_weekday_Monday  \\\n",
      "cdtaCode                                          \n",
      "BK01                                   863338.0   \n",
      "\n",
      "          Entry_total_trip_count_weekday_Saturday  \\\n",
      "cdtaCode                                            \n",
      "BK01                                     529582.0   \n",
      "\n",
      "          Entry_total_trip_count_weekday_Sunday  \\\n",
      "cdtaCode                                          \n",
      "BK01                                   534670.0   \n",
      "\n",
      "          Entry_total_trip_count_weekday_Thursday  \\\n",
      "cdtaCode                                            \n",
      "BK01                                     984481.0   \n",
      "\n",
      "          Entry_total_trip_count_weekday_Tuesday  \\\n",
      "cdtaCode                                           \n",
      "BK01                                    953658.0   \n",
      "\n",
      "          Entry_total_trip_count_weekday_Wednesday  \n",
      "cdtaCode                                            \n",
      "BK01                                      985648.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1422832948.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  entry_weekday_count_cdta = weekday_entry_stations.groupby(['cdtaCode', 'Station_Readings_Entry_weekday']).sum().reset_index()\\\n",
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1422832948.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  exit_weekday_count_cdta = weekday_exit_stations.groupby(['cdtaCode', 'Station_Readings_Exit_weekday']).sum().reset_index()\\\n"
     ]
    }
   ],
   "source": [
    "#6. Calculate CDTA Weekday wise (Sunday to Saturday ) NetEntries and NetExits\n",
    "\n",
    "print(mta_df.columns)\n",
    "weekday_entry_stations = mta_df.groupby(['Station_Readings_Entry_weekday','station'])[\"net_entries\"].sum().reset_index().copy()\n",
    "weekday_exit_stations = mta_df.groupby(['Station_Readings_Exit_weekday','station'])[\"net_exits\"].sum().reset_index().copy()\n",
    "\n",
    "weekday_entry_stations['cdtaCode'] = weekday_entry_stations['station'].map(cdta_station_dict).dropna()\n",
    "weekday_exit_stations['cdtaCode'] = weekday_exit_stations['station'].map(cdta_station_dict).dropna()\n",
    "\n",
    " ## Entry Weekday count by CDTA\n",
    "entry_weekday_count_cdta = weekday_entry_stations.groupby(['cdtaCode', 'Station_Readings_Entry_weekday']).sum().reset_index()\\\n",
    "    [['cdtaCode', 'Station_Readings_Entry_weekday','net_entries']].pivot(index='cdtaCode', columns=\"Station_Readings_Entry_weekday\", values=\"net_entries\")\n",
    "entry_weekday_count_cdta.columns = [\"Entry_total_trip_count_weekday_\" + str(col) for col in entry_weekday_count_cdta.columns]\n",
    "\n",
    " ## Exit Weekday count by CDTA\n",
    "exit_weekday_count_cdta = weekday_exit_stations.groupby(['cdtaCode', 'Station_Readings_Exit_weekday']).sum().reset_index()\\\n",
    "    [['cdtaCode', 'Station_Readings_Exit_weekday','net_exits']].pivot(index='cdtaCode', columns=\"Station_Readings_Exit_weekday\", values=\"net_exits\")\n",
    "exit_weekday_count_cdta.columns = [\"Exit_total_trip_count_weekday_\" + str(col) for col in exit_weekday_count_cdta.columns]\n",
    "\n",
    "print(exit_weekday_count_cdta.shape)\n",
    "print(entry_weekday_count_cdta.shape)\n",
    "\n",
    "print(exit_weekday_count_cdta.head(1))\n",
    "print(entry_weekday_count_cdta.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['station', 'entries', 'exits', 'net_entries', 'net_exits',\n",
      "       'net_traffic', 'Station_Readings_Exit_weekday',\n",
      "       'Station_Readings_Exit_year_month', 'Station_Readings_Exit_day',\n",
      "       'Station_Readings_Exit_hour', 'Station_Readings_Entry_weekday',\n",
      "       'Station_Readings_Entry_year_month', 'Station_Readings_Entry_day',\n",
      "       'Station_Readings_Entry_hour'],\n",
      "      dtype='object')\n",
      "(57, 6)\n",
      "(57, 6)\n",
      "          Exit_total_trip_count_year_month_2022-01  \\\n",
      "cdtaCode                                             \n",
      "BK01                                     1484602.0   \n",
      "\n",
      "          Exit_total_trip_count_year_month_2022-02  \\\n",
      "cdtaCode                                             \n",
      "BK01                                     1563017.0   \n",
      "\n",
      "          Exit_total_trip_count_year_month_2022-03  \\\n",
      "cdtaCode                                             \n",
      "BK01                                     1887375.0   \n",
      "\n",
      "          Exit_total_trip_count_year_month_2022-04  \\\n",
      "cdtaCode                                             \n",
      "BK01                                     1788293.0   \n",
      "\n",
      "          Exit_total_trip_count_year_month_2022-05  \\\n",
      "cdtaCode                                             \n",
      "BK01                                     1909177.0   \n",
      "\n",
      "          Exit_total_trip_count_year_month_2022-06  \n",
      "cdtaCode                                            \n",
      "BK01                                     1504024.0  \n",
      "          Entry_total_trip_count_year_month_2022-01  \\\n",
      "cdtaCode                                              \n",
      "BK01                                       896732.0   \n",
      "\n",
      "          Entry_total_trip_count_year_month_2022-02  \\\n",
      "cdtaCode                                              \n",
      "BK01                                       940687.0   \n",
      "\n",
      "          Entry_total_trip_count_year_month_2022-03  \\\n",
      "cdtaCode                                              \n",
      "BK01                                      1106402.0   \n",
      "\n",
      "          Entry_total_trip_count_year_month_2022-04  \\\n",
      "cdtaCode                                              \n",
      "BK01                                      1008330.0   \n",
      "\n",
      "          Entry_total_trip_count_year_month_2022-05  \\\n",
      "cdtaCode                                              \n",
      "BK01                                      1057708.0   \n",
      "\n",
      "          Entry_total_trip_count_year_month_2022-06  \n",
      "cdtaCode                                             \n",
      "BK01                                       803911.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1830722939.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  entry_year_month_count_cdta = year_month_entry_stations.groupby(['cdtaCode', 'Station_Readings_Entry_year_month']).sum().reset_index()\\\n",
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\1830722939.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  exit_year_month_count_cdta = year_month_exit_stations.groupby(['cdtaCode', 'Station_Readings_Exit_year_month']).sum().reset_index()\\\n"
     ]
    }
   ],
   "source": [
    "#7. Calculate CDTA Year and Month wise NetEntries and NetExits\n",
    "\n",
    "print(mta_df.columns)\n",
    "year_month_entry_stations = mta_df.groupby(['Station_Readings_Entry_year_month','station'])[\"net_entries\"].sum().reset_index().copy()\n",
    "year_month_exit_stations = mta_df.groupby(['Station_Readings_Exit_year_month','station'])[\"net_exits\"].sum().reset_index().copy()\n",
    "\n",
    "year_month_entry_stations['cdtaCode'] = year_month_entry_stations['station'].map(cdta_station_dict).dropna()\n",
    "year_month_exit_stations['cdtaCode'] = year_month_exit_stations['station'].map(cdta_station_dict).dropna()\n",
    "\n",
    " ## Entry Year and Monthwise count by CDTA\n",
    "entry_year_month_count_cdta = year_month_entry_stations.groupby(['cdtaCode', 'Station_Readings_Entry_year_month']).sum().reset_index()\\\n",
    "    [['cdtaCode', 'Station_Readings_Entry_year_month','net_entries']].pivot(index='cdtaCode', columns=\"Station_Readings_Entry_year_month\", values=\"net_entries\")\n",
    "entry_year_month_count_cdta.columns = [\"Entry_total_trip_count_year_month_\" + str(col) for col in entry_year_month_count_cdta.columns]\n",
    "\n",
    " ## Exit Year and Monthwise count by CDTA\n",
    "exit_year_month_count_cdta = year_month_exit_stations.groupby(['cdtaCode', 'Station_Readings_Exit_year_month']).sum().reset_index()\\\n",
    "    [['cdtaCode', 'Station_Readings_Exit_year_month','net_exits']].pivot(index='cdtaCode', columns=\"Station_Readings_Exit_year_month\", values=\"net_exits\")\n",
    "exit_year_month_count_cdta.columns = [\"Exit_total_trip_count_year_month_\" + str(col) for col in exit_year_month_count_cdta.columns]\n",
    "\n",
    "print(exit_year_month_count_cdta.shape)\n",
    "print(entry_year_month_count_cdta.shape)\n",
    "print(exit_year_month_count_cdta.head(1))\n",
    "print(entry_year_month_count_cdta.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 3)\n",
      "['BK01', 'BK02', 'BK03', 'BK04', 'BK05', 'BK06', 'BK07', 'BK09', 'BK10', 'BK11', 'BK12', 'BK13', 'BK14', 'BK15', 'BK16', 'BK17', 'BK18', 'BK55', 'BX01', 'BX02', 'BX03', 'BX04', 'BX05', 'BX06', 'BX07', 'BX08', 'BX09', 'BX10', 'BX11', 'BX12', 'MN01', 'MN02', 'MN03', 'MN04', 'MN05', 'MN06', 'MN07', 'MN08', 'MN09', 'MN10', 'MN11', 'MN12', 'MN64', 'QN01', 'QN02', 'QN03', 'QN04', 'QN05', 'QN06', 'QN07', 'QN09', 'QN10', 'QN12', 'QN14', 'QN81', 'QN83', 'SI01']\n",
      "Index(['CDTAName', 'borough', 'geometry', 'net_entries', 'net_exits',\n",
      "       'Entry_total_trip_count_day_1', 'Entry_total_trip_count_day_2',\n",
      "       'Entry_total_trip_count_day_3', 'Entry_total_trip_count_day_4',\n",
      "       'Entry_total_trip_count_day_5',\n",
      "       ...\n",
      "       'Entry_total_trip_count_year_month_2022-03',\n",
      "       'Entry_total_trip_count_year_month_2022-04',\n",
      "       'Entry_total_trip_count_year_month_2022-05',\n",
      "       'Entry_total_trip_count_year_month_2022-06',\n",
      "       'Exit_total_trip_count_year_month_2022-01',\n",
      "       'Exit_total_trip_count_year_month_2022-02',\n",
      "       'Exit_total_trip_count_year_month_2022-03',\n",
      "       'Exit_total_trip_count_year_month_2022-04',\n",
      "       'Exit_total_trip_count_year_month_2022-05',\n",
      "       'Exit_total_trip_count_year_month_2022-06'],\n",
      "      dtype='object', length=141)\n",
      "CDTAName                                    BK01 Williamsburg-Greenpoint (CD 1 Equivalent)...\n",
      "borough                                     BkBkBkBkBkBkBkBkBkBkBkBkBkBkBkBkBkBkBxBxBxBxBx...\n",
      "net_entries                                                                       321656010.0\n",
      "net_exits                                                                         394672773.0\n",
      "Entry_total_trip_count_day_1                                                       10588376.0\n",
      "                                                                  ...                        \n",
      "Exit_total_trip_count_year_month_2022-02                                           60119505.0\n",
      "Exit_total_trip_count_year_month_2022-03                                           72693201.0\n",
      "Exit_total_trip_count_year_month_2022-04                                           70305780.0\n",
      "Exit_total_trip_count_year_month_2022-05                                           74390310.0\n",
      "Exit_total_trip_count_year_month_2022-06                                           59965597.0\n",
      "Length: 140, dtype: object\n",
      "(57, 141)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panch\\AppData\\Local\\Temp\\ipykernel_24064\\3546936648.py:15: FutureWarning: The default value of numeric_only in GeoDataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  print(cdta_df.sum())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cdta_burough_poly_df = stationWithCdta.set_index(\"cdtaCode\")[[\"CDTAName\", \"borough\",\"geometry\"]].drop_duplicates()\n",
    "cdta_burough_poly_df = cdta_burough_poly_df.drop('BK08')\n",
    "\n",
    "condition = ~((cdta_burough_poly_df['CDTAName'] == 'BX08 Riverdale-Kingsbridge-Marble Hill (CD 8 Approximation)') & (cdta_burough_poly_df['borough'] == 'M'))\n",
    "cdta_burough_poly_df = cdta_burough_poly_df[ condition ]\n",
    "\n",
    "print(cdta_burough_poly_df.shape)\n",
    "\n",
    "#cdta_burough_poly_df.to_csv('temp99.csv')\n",
    "print(net_entry_cdta.index.tolist())\n",
    "\n",
    "cdta_df = pd.concat([cdta_burough_poly_df,net_entry_cdta,net_exit_cdta,entry_day_count_cdta,exit_day_count_cdta,entry_hour_count_cdta,exit_hour_count_cdta,entry_weekday_count_cdta,exit_weekday_count_cdta,entry_year_month_count_cdta,exit_year_month_count_cdta], axis=1)\n",
    "cdta_df.to_csv('subway_cdta.csv')\n",
    "print(cdta_df.columns)\n",
    "print(cdta_df.sum())\n",
    "print(cdta_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
